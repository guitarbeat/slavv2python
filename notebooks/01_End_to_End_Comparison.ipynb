{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# End-to-End Comparison Workflow\n",
                "\n",
                "This notebook provides a **one-click solution** to run the complete SLAVV comparison pipeline:\n",
                "1.  **Run MATLAB Vectorization** (External)\n",
                "2.  **Run Python Vectorization** (Native)\n",
                "3.  **Compare Results** (Statistical & Structural)\n",
                "4.  **Generate Report**\n",
                "\n",
                "### Prerequisites\n",
                "- Ensure you have run `00_Setup_and_Validation.ipynb` first.\n",
                "- Ensure MATLAB is installed and licensed."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "%load_ext autoreload\n",
                "%autoreload 2\n",
                "\n",
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "import shutil\n",
                "\n",
                "# Import orchestration logic\n",
                "from tools.comparison import load_parameters, orchestrate_comparison\n",
                "\n",
                "print(\"✅ Orchestration modules loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "config_header",
            "metadata": {},
            "source": [
                "## Configuration\n",
                "\n",
                "Configure your inputs below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === INPUTS ===\n",
                "input_file = \"tests/data/slavv_test_volume.tif\"\n",
                "matlab_executable = shutil.which('matlab') or \"\"\n",
                "\n",
                "# Output directory (auto-timestamped by default)\n",
                "# Set output_dir = None to use default 'experiments/YYYYMMDD_HHMMSS' (formerly 'comparisons')\n",
                "output_dir = None \n",
                "\n",
                "# Flags\n",
                "SKIP_MATLAB = False  # Set to True to re-use previous MATLAB run (requires manual config) or skip\n",
                "SKIP_PYTHON = False\n",
                "\n",
                "print(f\"Input: {input_file}\")\n",
                "print(f\"MATLAB: {matlab_executable}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "run_header",
            "metadata": {},
            "source": [
                "## Run Pipeline\n",
                "\n",
                "Execute the cell below to start the full comparison. This may take several minutes depending on the volume size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Resolve paths\n",
                "project_root = Path('..').resolve()\n",
                "input_path = str(project_root / input_file)\n",
                "\n",
                "# Load default parameters\n",
                "params = load_parameters()\n",
                "\n",
                "# Determine output directory\n",
                "if output_dir:\n",
                "    out_path = Path(output_dir)\n",
                "else:\n",
                "    from datetime import datetime\n",
                "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "    out_path = project_root / 'experiments' / f'{timestamp}_comparison'\n",
                "\n",
                "print(f\"Starting execution... Output: {out_path}\")\n",
                "\n",
                "# Run Orchestration\n",
                "status = orchestrate_comparison(\n",
                "    input_file=input_path,\n",
                "    output_dir=out_path,\n",
                "    matlab_path=matlab_executable,\n",
                "    project_root=project_root,\n",
                "    params=params,\n",
                "    skip_matlab=SKIP_MATLAB,\n",
                "    skip_python=SKIP_PYTHON\n",
                ")\n",
                "\n",
                "if status == 0:\n",
                "    print(\"\\n✅ Comparison completed successfully!\")\n",
                "    print(f\"Results saved to: {out_path}\")\n",
                "else:\n",
                "    print(\"\\n❌ Comparison failed or completed with errors.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "next_steps",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Now that the results are generated, use the dashboard to explore the visual differences.\n",
                "\n",
                "- [Open Comparison Dashboard](04_Comparison_Dashboard.ipynb)\n",
                "- [Open Statistical Analysis](05_Statistical_Analysis.ipynb)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (SLAVV)",
            "language": "python",
            "name": "slavv-env"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}